{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제일 간단한 수준의 linear regression의 코드를 리뷰해보자\n",
    "    gradient descent에 따른 W, b 값의 변화를 plot으로 simulation 처리를 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1., 2., 3., 4., 6., 7., 8., 9., 10.]\n",
    "y_groundtruth = [1., 2., 3., 4., 6., 7., 8., 9., 10.]\n",
    "\n",
    "# 임의의 값으로 초기값을 설정 : 일반적으로 random 값을 준다. - 성능에 영향을 주기 때문에 여러 방법론이 있다 (xavier initilization 참고)\n",
    "init_W = 0.3\n",
    "init_b = -0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable([init_W], dtype=tf.float32)\n",
    "b = tf.Variable([init_b], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "# Hypothesis / y hat\n",
    "y_hat = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sess.run(y_hat, {x: x_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sess.run(loss, {x: x_train, y: y_groundtruth}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "loss = tf.reduce_sum(tf.square(y_hat - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to incorrect defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_W = [init_W]\n",
    "plot_b = [init_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0 loss:  198.21 W:  [ 0.83400005] b:  [-0.22460002]\n",
      "step:  100 loss:  0.0360485 W:  [ 1.0184207] b:  [-0.13188648]\n",
      "step:  200 loss:  0.0160652 W:  [ 1.01229727] b:  [-0.08804414]\n",
      "step:  300 loss:  0.00715956 W:  [ 1.00820935] b:  [-0.05877613]\n",
      "step:  400 loss:  0.00319074 W:  [ 1.00548029] b:  [-0.03923749]\n",
      "step:  500 loss:  0.00142196 W:  [ 1.00365853] b:  [-0.02619397]\n",
      "step:  600 loss:  0.000633706 W:  [ 1.00244236] b:  [-0.01748639]\n",
      "step:  700 loss:  0.000282412 W:  [ 1.00163043] b:  [-0.0116735]\n",
      "step:  800 loss:  0.000125854 W:  [ 1.0010885] b:  [-0.00779293]\n",
      "step:  900 loss:  5.60929e-05 W:  [ 1.00072658] b:  [-0.00520241]\n",
      "step:  1000 loss:  2.49994e-05 W:  [ 1.00048506] b:  [-0.003473]\n",
      "step:  1100 loss:  1.11408e-05 W:  [ 1.00032389] b:  [-0.00231853]\n",
      "step:  1200 loss:  4.96314e-06 W:  [ 1.00021625] b:  [-0.00154776]\n",
      "step:  1300 loss:  2.21253e-06 W:  [ 1.00014436] b:  [-0.00103322]\n",
      "step:  1400 loss:  9.86229e-07 W:  [ 1.00009632] b:  [-0.00068969]\n",
      "step:  1500 loss:  4.39389e-07 W:  [ 1.00006437] b:  [-0.00046043]\n",
      "step:  1600 loss:  1.95414e-07 W:  [ 1.00004292] b:  [-0.00030738]\n",
      "step:  1700 loss:  8.73167e-08 W:  [ 1.00002873] b:  [-0.00020529]\n",
      "step:  1800 loss:  3.88774e-08 W:  [ 1.00001907] b:  [-0.00013701]\n",
      "step:  1900 loss:  1.74161e-08 W:  [ 1.00001276] b:  [ -9.14873235e-05]\n",
      "step:  2000 loss:  7.77086e-09 W:  [ 1.00000858] b:  [ -6.11309079e-05]\n",
      "step:  2100 loss:  3.45699e-09 W:  [ 1.00000572] b:  [ -4.08540218e-05]\n",
      "step:  2200 loss:  1.56209e-09 W:  [ 1.00000381] b:  [ -2.74278300e-05]\n",
      "step:  2300 loss:  7.35358e-10 W:  [ 1.0000025] b:  [ -1.84858218e-05]\n",
      "step:  2400 loss:  3.3431e-10 W:  [ 1.00000179] b:  [ -1.24942453e-05]\n",
      "step:  2500 loss:  1.37849e-10 W:  [ 1.00000119] b:  [ -8.34576258e-06]\n",
      "step:  2600 loss:  7.13705e-11 W:  [ 1.00000083] b:  [ -5.75069544e-06]\n",
      "step:  2700 loss:  3.94067e-11 W:  [ 1.0000006] b:  [ -4.18345189e-06]\n",
      "step:  2800 loss:  2.25384e-11 W:  [ 1.00000048] b:  [ -3.20808067e-06]\n",
      "step:  2900 loss:  1.5266e-11 W:  [ 1.00000048] b:  [ -2.67831274e-06]\n",
      "step:  3000 loss:  1.28608e-11 W:  [ 1.00000036] b:  [ -2.13388307e-06]\n",
      "step:  3100 loss:  1.13261e-11 W:  [ 1.00000036] b:  [ -2.02086972e-06]\n",
      "step:  3200 loss:  1.13261e-11 W:  [ 1.00000036] b:  [ -1.99701822e-06]\n",
      "step:  3300 loss:  1.11307e-11 W:  [ 1.00000036] b:  [ -1.98486509e-06]\n",
      "step:  3400 loss:  1.11307e-11 W:  [ 1.00000036] b:  [ -1.97295071e-06]\n",
      "step:  3500 loss:  3.83693e-12 W:  [ 1.00000024] b:  [ -1.52436883e-06]\n",
      "step:  3600 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  3700 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  3800 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  3900 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4000 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4100 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4200 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4300 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4400 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4500 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4600 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4700 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4800 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "step:  4900 loss:  6.0254e-12 W:  [ 1.00000024] b:  [ -1.42995520e-06]\n",
      "W: [ 1.00000024] b: [ -1.42995520e-06] loss : 6.0254e-12\n",
      "51 51\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    _, W_value, b_value, loss_value = sess.run([train, W, b, loss], {x: x_train, y: y_groundtruth})\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(\"step: \", step, \"loss: \", loss_value, \"W: \", W_value, \"b: \", b_value)\n",
    "        plot_W = np.append(plot_W, W_value)\n",
    "        plot_b = np.append(plot_b, b_value)\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_groundtruth})\n",
    "print(\"W: %s b: %s loss : %s\"%(curr_W, curr_b, curr_loss))\n",
    "\n",
    "print(len(plot_W), len(plot_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 5.0, y: [ 4.99999952]\n"
     ]
    }
   ],
   "source": [
    "x_test = 5.\n",
    "y_predict = sess.run(y_hat, {x: x_test})\n",
    "print(\"x: %s, y: %s\"%(x_test, y_predict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
